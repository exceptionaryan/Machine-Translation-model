{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Referenced mainly from - https://torchtutorialstaging.z5.web.core.windows.net/beginner/translation_transformer.html\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3xq85Cvyv6OG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-1mRcl-ygzQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4d8ea7-2823-4a14-ad08-c99023bcbc0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6a0c4aa5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import math\n",
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from typing import Iterable, List\n",
        "\n",
        "from torch import Tensor\n",
        "import io\n",
        "import time\n",
        "\n",
        "torch.manual_seed(0)\n",
        "# torch.use_deterministic_algorithms(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download xx_ent_wiki_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVtm8MagtE3w",
        "outputId": "7e90eccb-243f-4c4f-8d83-b3a3e0e8f66e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-14 22:25:52.410516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-14 22:25:53.478436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-14 22:25:55.726420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-14 22:25:55.727052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-14 22:25:55.727312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xx-ent-wiki-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.5.0/xx_ent_wiki_sm-3.5.0-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from xx-ent-wiki-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('spacy', language='xx_ent_wiki_sm')\n",
        "\n",
        "text = \"यह हिंदी में टोकनाइज करने का उदाहरण है।\"\n",
        "\n",
        "tokens = tokenizer(text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-lIro24sbju",
        "outputId": "fe45f7f3-a155-4bac-e7ca-cf5d23771cd7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['यह', 'हिंदी', 'में', 'टोकनाइज', 'करने', 'का', 'उदाहरण', 'है', '।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.naive_bayes import LogisticRegression\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "label_dict = {-1:0,0:1,1:2}\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/eng_Hindi_data_train.csv\",header = None)\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/eng_Hindi_data_test_X.csv\",header = None)\n",
        "data.columns = [\"english_text\", \"hindi_text\"]\n",
        "test.columns = [\"hindi_text\"]\n",
        "data.head()\n",
        "# data.drop(columns = [\"text_id\"], inplace = True)\n",
        "# data['label'] = data['gold_label'].map(label_dict)\n",
        "trn_data = data.sample(frac=0.8, random_state=42)\n",
        "vl_data = data.drop(trn_data.index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrIBZp_pk0mO",
        "outputId": "ac179eef-b4d0-4d7c-cdaa-3955897e587f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JWtPE7EkGkJu",
        "outputId": "4351904c-7316-488c-8ed5-8caa63a13e38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_text  \\\n",
              "0  and deliver us by Thy mercy from the people of...   \n",
              "1               Transformed position of fourth point   \n",
              "2  Oh, woe to me; I wish I never took so - and - ...   \n",
              "3  The PS file is to be translated into a PDF fil...   \n",
              "4                   Receiving LDAP search results...   \n",
              "\n",
              "                                          hindi_text  \n",
              "0  और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...  \n",
              "1                     चौथे बिन्दु का रूपांतरित स्थान  \n",
              "2    हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता  \n",
              "3  पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...  \n",
              "4                       LDAP खोज परिणाम पा रहा है...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4eef0d8b-3c5f-4a27-b96d-0049148bfb2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_text</th>\n",
              "      <th>hindi_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and deliver us by Thy mercy from the people of...</td>\n",
              "      <td>और अपनी रहमत से हमें इन काफ़िर लोगों (के नीचे)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformed position of fourth point</td>\n",
              "      <td>चौथे बिन्दु का रूपांतरित स्थान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oh, woe to me; I wish I never took so - and - ...</td>\n",
              "      <td>हाए अफसोस काश मै फला शख्स को अपना दोस्त न बनाता</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The PS file is to be translated into a PDF fil...</td>\n",
              "      <td>पीएस2पीडीएफ के इस्तेमाल से पीएस फ़ाइल को पीडीए...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Receiving LDAP search results...</td>\n",
              "      <td>LDAP खोज परिणाम पा रहा है...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4eef0d8b-3c5f-4a27-b96d-0049148bfb2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4eef0d8b-3c5f-4a27-b96d-0049148bfb2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4eef0d8b-3c5f-4a27-b96d-0049148bfb2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_data = trn_data.reset_index(drop = True)\n",
        "vl_data = vl_data.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "pKhMPs9RzkWu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "\n",
        "class MyIterableDataset(IterableDataset):\n",
        "    def __init__(self, english_sentences, hindi_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.hindi_sentences = hindi_sentences\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for hindi_sentence, english_sentence in zip(self.hindi_sentences, self.english_sentences):\n",
        "            # Convert the sentences to tensors\n",
        "            # hindi_tensor = torch.tensor(hindi_sentence)\n",
        "            # english_tensor = torch.tensor(english_sentence)\n",
        "            \n",
        "            yield hindi_sentence, english_sentence\n",
        "\n",
        "# Example usage\n",
        "train_iter = MyIterableDataset(trn_data['hindi_text'], trn_data['english_text'])\n",
        "eval_iter = MyIterableDataset(vl_data['hindi_text'], vl_data['english_text'])\n"
      ],
      "metadata": {
        "id": "qoYIzg4shGVx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hi_tokenizer = get_tokenizer('spacy', language='xx_ent_wiki_sm')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "6y0ml-G9oRaN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "SRC_LANGUAGE = 'hi'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "token_transform['hi'] = get_tokenizer('spacy', language='xx_ent_wiki_sm')\n",
        "token_transform['en'] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {'hi': 1, 'en': 0}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "train_iter = MyIterableDataset(trn_data['hindi_text'], trn_data['english_text'])\n",
        "vocab_transform['hi'] = build_vocab_from_iterator(yield_tokens(train_iter, 'hi'),\n",
        "                                                min_freq=1,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True,\n",
        "                                                max_tokens = 5000)\n",
        "train_iter = MyIterableDataset(trn_data['hindi_text'], trn_data['english_text'])\n",
        "vocab_transform['en'] = build_vocab_from_iterator(yield_tokens(train_iter, 'en'),\n",
        "                                                min_freq=1,\n",
        "                                                specials=special_symbols,\n",
        "                                                special_first=True,\n",
        "                                                max_tokens = 5000)\n",
        "\n",
        "vocab_transform['hi'].set_default_index(UNK_IDX)\n",
        "vocab_transform['en'].set_default_index(UNK_IDX)\n"
      ],
      "metadata": {
        "id": "kL6RXWe8qPFl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_transform['en'].get_stoi().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS8GKlXCDmeG",
        "outputId": "00e847eb-028a-4c2c-c75c-c2af91add2c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['kinsfolk', 'humiliated', 'harmdoers', 'goal', 'glance', 'fabricating', 'enters', 'd:%', 'cows', 'construct', 'checksum', 'blameworthy', 'bargain', 'announced', 'amass', 'abasement', 'Printing', 'Pine', 'News', 'Log', 'Deprecated', 'Copies', 'Automatic', 'tread', 'toucheth', 'suckling', 'succeeded', 'stock', 'relented', 'picked', 'omen', 'obeying', 'luminous', 'kindle', 'inwardly', 'hot', 'hopes', 'hoard', 'harsh', 'friendship', 'focused', 'fables', 'expands', 'eternal', 'en', 'devoured', 'decrypt', 'crookedness', 'boat', 'bethink', 'befalleth', 'awaiting', 'attractive', 'assist', 'ambush', 'absent', 'White', 'Signing', 'Receiving', 'Python', 'greet', 'Pre', 'Magog', 'JavaScript', 'Inline', 'ISO9660', 'Global', 'Deal', 'Busy', '02i', 'workday', 'wing', 'weary', 'vanished', 'unwillingly', 'thunderbolt', 'strives', 'striking', 'sights', 'rocks', 'resume', 'restricts', 'quicken', 'Hallowed', 'prompt', 'policy', 'pleasant', 'paying', 'opposed', 'mistake', 'labour', 'invites', 'invitations', 'ink', 'injury', 'inherited', 'hospitality', 'gains', 'helpless', 'farther', 'executed', 'dying', 'device%', 'describe', 'degree', 'daemon', 'cries', 'categories', 'carries', 'leader', 'buried', 'brocade', 'bidding', 'tower', 'beheld', 'deserving', 'avatar', 'autocompletion', 'ant', 'Wherein', 'Real', 'borne', 'Once', 'Office', 'Fog', 'Criterion', '02i:%', 'writeable', 'walking', 'unavailable', 'treacherous', 'strove', 'stopped', 'slower', 'role', 'roads', 'reconciliation', 'preaching', 'overlook', 'morn', 'meat', 'fulfilment', 'magnify', 'livestock', 'listeth', 'graphical', 'expose', 'carbon', 'calleth', 'absolute', 'abroad', 'TLS', 'Store', 'Sinai', 'Redo', 'Ourselves', 'NNTP', 'Heavy', 'Evince', 'EOL', 'Deleting', 'Cancel', 'Invoke', '720', 'withdrew', 'watchful', 'tomorrow', 'circle', 'summon', 'semen', 'safely', 'refer', 'race', 'prone', 'practise', 'passphrase', 'olives', 'olive', 'mechanism', 'inspiration', 'imposed', 'ilah', 'gently', 'flood', 'fingers', 'drinks', 'difference', 'dictate', 'confirms', 'caption', 'beggar', 'beauty', 'aliha', 'Specifies', 'Night', 'Mar', 'Imran', 'Host', 'Cyrillic', 'Chance', 'Attendee', '14', '02', 'whisper', 'veils', 'transgressor', 'spouse', 'Helper', 'somewhat', 'slip', 'seventy', 'providers', 'lewdness', 'iniquity', 'heaviness', 'goeth', 'figure', 'fierce', 'fed', 'envoys', 'emptying', 'diminish', 'detect', 'corrupters', 'constrained', 'compelled', 'cleanse', 'bosom', 'achievement', 'Virtual', 'Unless', 'Spend', 'Signature', 'Rich', 'Reality', 'Prostrate', 'concerned', 'Properties', 'Ne', 'More', 'Creating', 'Control', 'Bear', 'Assistant', 'Zechariah', 'wrongs', 'workers', 'wolf', 'whereunder', 'wedlock', 'cost', 'wear', 'void', 'unawares', 'twenty', 'Street', 'transgresses', 'sites', 'tiding', 'thunder', 'spelling', 'shaped', 'Removing', 'serving', 'revenge', 'relent', 'pregnant', 'Severe', 'plaintext', 'performs', 'occur', 'humanity', 'beg', 'fetters', 'extra', 'executing', 'dutiful', 'disciples', 'devotional', 'deserve', 'defender', 'caller', 'breaking', 'ace', 'Viewer', 'Strike', 'Skype', 'Revelation', 'Muhsinun', 'Kill', 'relations', 'Internal', 'Fifth', 'Getting', 'Excellent', 'youths', 'hostile', 'weeping', 'versions', 'traveller', 'conscious', 'tears', 'statusbar', 'sidebar', 'shun', 'retreat', 'raging', 'primary', 'pastime', 'opposite', 'office', 'multiplied', 'mosque', 'inner', 'healing', 'haughty', 'hastening', 'hapless', 'forbearing', 'falsely', 'underlying', 'equivalent', 'disbelieveth', 'creators', 'choice', 'chapter', 'Forced', 'caught', 'calculation', 'bulk', 'bit', 'advised', 'Opens', 'activate', 'Column', 'Whomever', 'Surah', 'Sun', 'Permanently', 'Standard', 'SO', 'Psalms', 'Lock', 'Permission', 'Mine', 'IS', 'Huwa', 'Height', 'Earth', 'Am', 'Adds', 'kde', 'vertically', 'temptation', 'spite', 'slaughtering', 'reproach', 'proportioned', 'possibly', 'polytheist', 'Named', 'polygon', 'pasture', 'monks', 'modifying', 'maximize', 'logs', 'Thunderstorm', 'homecoming', 'fragments', 'forsaken', 'expired', 'excesses', 'discs', 'weep', 'defeated', 'crucify', 'EXIF', 'commandments', 'chance', 'belonged', 'beholders', 'beast', 'assembly', 'announce', 'amidst', 'amid', 'abstain', 'Recompense', 'Originator', 'Omnipotent', 'Buddy', 'Bow', 'Any', 'dearer', 'visibility', 'allege', 'truthfulness', 'torn', 'skies', 'repose', 'protected', 'priority', 'obvious', 'muster', 'Used', 'listened', 'libraries', 'load%', 'letter', 'invitation', 'doomed', 'disown', 'devising', 'comrade', 'chastity', 'beginning', 'bank', 'assert', 'aloud', 'affection', 'accountable', 'acceptance', 'Yourself', 'Week', 'identity', 'Verse', 'Scanning', 'Marcus', 'hole', 'disregard', 'Delight', 'Client', 'was:%', 'Missing', 'views', 'user%', 'united', 'google', 'players', 'thirds', 'spam', 'smoke', 'rope', 'reprieved', 'repented', 'purer', 'produces', 'preserved', 'overturned', 'Bliss', 'navigator', 'maximized', 'bag', 'looked', 'totally', 'implementation', 'happens', 'freely', 'features', 'fabricates', 'f', 'exclaimed', 'encountered', 'e,%', 'doubts', 'distinction', 'deprived', 'burdened', 'Wali', 'USA', 'Religion', 'Power', 'MA', 've', 'tyrant', 'transport', 'horizon', 'trace', 'threat', 'tags', 'ridicule', 'rent', 'publish', 'plenty', 'organizer', 'job', 'importing', 'illa', 'homage', 'hastened', 'greatly', 'garment', 'fun', 'failure', 'earns', 'difficulty', 'columns', 'buddy', 'bought', 'supplicate', 'bequeathed', 'anon', 'adopt', 'Write', 'Version', 'stretch', 'Throw', 'Proxy', 'Potent', 'Job', 'Extract', 'Creates', 'Black', 'widgets', 'visits', 'violent', 'violence', 'tillage', 'symbols', 'straying', 'sounds', 'favor', 'replies', 'persecution', 'orders', 'node', 'miracle', 'disputes', 'maturity', 'lowest', 'accepting', 'inscribed', 'indicated', 'guards', 'foe', 'drown', 'decrees', 'corresponding', 'context', 'knees', 'chains', 'bodies', 'abandoned', 'b%', 'Vertical', 'Unsubscribe', 'Torment', 'formats', 'Ours', 'Madyan', 'Ilah', 'devouring', '2006', 'vCard', 'townships', 'touches', 'fairly', 'total', 'thyself', 'thrust', 'recommended', 'sufficeth', 'specifies', 'sail', 'recover', 'dragged', 'punishes', 'lt', 'labels', 'jack', 'ingratitude', 'ignore', 'guiding', 'gotten', 'spared', 'fools', 'foolish', 'effort', 'door', 'disperse', 'dispensation', 'disgraced', 'country', 'forego', 'clot', 'cdrecord', 'bah', 'ate', 'perception', 'agreement', 'Zachariah', 'season', 'Source', 'Really', 'Mac', 'Informed', 'scope', 'Enjoy', 'y', 'worshippers', 'seated', 'wings', 'west', 'wandering', 'type%', 'troops', 'trigger', 'spare', 'inclined', 'resurrection', 'purity', 'privately', 'parsing', 'multitude', 'invoked', 'gentle', 'erring', 'distinguished', 'disputing', 'digiKam', 'steeped', 'delusion', 'distinguish', 'conferred', 'concealed', 'big', 'journeyed', 'becometh', 'Meeting', 'assume', 'Up', 'Restore', 'Mailbox', 'lifted', 'Flag', 'deem', 'Field', '©', 'wayfarer', 'unsupported', 'spell', 'rights', 'shining', 'Output', 'repents', 'relation', 'rear', 'piece', 'offerings', 'threads', 'narrate', 'kinship', 'ascribing', 'inflict', 'fled', 'factions', 'contend', 'by%', 'ascend', 'animation', 'Shuaib', 'Shows', 'determining', 'Rotate', 'Likewise', 'incorrect', 'Cry', 'Again', 'straitened', 'rightful', 'forbids', 'flight', 'fit', 'Bains', 'entrusted', 'eager', 'disables', 'readable', 'advanced', 'arrogance', 'aggression', 'formatted', 'accursed', 'West', 'Retribution', 'Rahman', 'Ka', 'Hold', 'demand', 'Font', 'CC', 'Beholder', 'Back', 'welcome', 'bowing', 'turneth', 'penitently', 'teaching', 'mails', 'steps', 'embedded', 'region', 'reform', 'reduced', 'reaching', 'sperm', 'practice', 'Re', 'perceived', 'message:%', 'bridal', 'originates', 'volume', 'measured', 'letters', 'intend', 'drove', 'victors', 'hamstrung', 'gnome', 'gaze', 'reality', 'followeth', 'exclusive', 'earthquake', 'export', 'drew', 'drawing', 'divinity', 'distinct', 'Moving', 'qub', 'dealt', 'befallen', 'ark', 'Auliya', 'accord', 'Tabari', 'TO', 'accuse', 'Sender', 'Seek', 'rush', 'Pray', 'Pidgin', 'benevolence', '90', 'Men', 'MD5', 'Folders', 'resurrect', 'willing', 'sinner', 'reload', '23', 'reclining', 'delivery', 'lean', 'declaration', 'journeying', 'issue', 'immed', 'imagined', 'hardened', 'flocks', 'extend', 'expected', 'eating', 'directories', 'depth', 'Receive', 'contained', 'completely', 'checking', 'celebrate', 'business', 'block', 'WARRANTY', 'Program', 'URIs', 'Snow', 'Scriptures', 'Rename', 'MERCHANTABILITY', 'John', 'A1', 'Iqamat', 'FOR', 'Date', 'Cogl', 'ANY', 'trouble', 'suffice', 'rivals', 'rescue', 'wash', 'performing', 'redistribute', 'pictures', 'oppressors', 'mindful', 'maidens', 'lived', 'horses', 'gush', 'explained', 'edge', 'covers', 'Lout', 'comprehend', 'burst', 'brightness', 'abased', 'apprehend', 'abandon', 'neglect', 'amends', 'Options', '11', 'captive', 'Law', 'Kingdom', 'First', 'nnn', 'young', 'ultimate', 'sanctity', 'tales', 'summoned', 'prisoners', 'starts', 'undone', 'smaller', 'ran', 'similitudes', 'showing', 'shouldst', 'sheep', 'schema', 'red', 'charset', 'public', 'posterity', 'searched', 'attention', 'persist', 'hills', 'glass', 'gets', 'fluid', 'felicitous', 'doors', 'bringing', 'assemble', 'algorithm', 'poet', 'understood', 'Unicode', 'Linux', 'Blessings', 'subfolders', 'shake', 'sanctuary', 'responsible', 'religious', 'diff', 'queen', 'milk', 'puts', 'prohibited', 'poured', 'manually', 'l', 'jobs', 'impugned', 'humbly', 'booty', 'disposed', 'differences', 'trustee', 'compeers', 'commits', 'Valid', 'chooses', 'causing', 'ancient', 'Unrecognized', 'Port', 'Good', 'lords', 'F', 'East', 'Doom', '2003', 'watching', 'observing', 'wander', 'tokens', 'strengthen', 'Drag', 'prove', 'awhile', 'Cut', 'programs', 'phrase', 'oppress', 'oppose', 'mustered', 'moves', 'insolent', 'hearken', 'forged', 'class', 'addition', 'acting', 'abomination', 'Thamood', 'Fight', 'flung', 'Cave', 'BCC', 'weigh', 'vast', 'usually', 'tremendous', 'tableau', 'swine', 'Pilgrimage', 'succession', 'stage', 'specific', 'Level', 'appearance', 'regret', 'regards', 'real', 'behave', 'moment', 'method', 'lusts', 'leading', 'keeps', 'miracles', 'Whereas', 'justified', 'inheritors', 'getting', 'exclusively', 'resolved', 'division', 'wipe', 'wouldst', 'discard', 'Secure', 'directed', 'almost', 'Wisdom', 'Sort', 'Requested', 'GTK', 'Perhaps', 'sparing', 'Haman', 'Don', 'Common', 'willeth', 'Scale', 'invited', 'suffered', 'machine', 'slaughtered', 'keeping', 'render', 'net', 'latter', 'flame', 'fish', 'Toolbar', 'directly', 'denial', 'blast', 'availed', 'attendee', 'whereby', 'afore', 'Trustee', 'Observe', 'shape', 'Inbox', 'Format', 'bind', 'whilst', 'DVDs', 'Bar', ':)', '2007', 'sweet', 'witnessed', 'weakness', 'variable', 'appointments', 'stray', 'repentant', 'sincerely', 'sickness', 'Information', 'shout', 'repository', 'Compose', 'receiving', 'protecting', 'Selection', 'pearls', 'oppression', 'numerous', 'immediately', 'heir', 'revision', 'habitation', 'frame', 'exceeded', 'incumbent', 'encompassed', 'Split', 'emigrated', 'destined', 'chaste', 'breast', 'attained', 'integer', 'SOCKS', 'Recall', 'detailed', 'upper', 'Hath', 'Determines', 'Being', 'ability', 'adopted', '100', 'yellow', 'thoughts', 'idolater', 'preferences', 'supporter', 'stood', 'rejoicing', 'pour', 'penitent', 'parameters', 'migrated', 'hadst', 'intended', 'Compress', 'imagine', 'illegal', 'gallery', 'foot', 'filtering', 'extreme', 'Abode', 'divine', 'carrying', 'dislike', 'deep', 'counted', 'crash', 'served', 'communities', 'closer', 'bin', 'Headers', 'at%', 'guilt', 'Talk', 'appropriate', 'aileth', 'Replace', 'RSA', 'Paste', 'Mujrimun', 'Minimum', 'Franklin', 'Everlasting', 'Connector', 'wrought', 'speaking', 'ride', 'requital', 'relate', 'recorded', 'playlist', 'evils', 'dread', 'doesn', 'Press', 'declared', 'creed', 'bid', 'alarms', 'metadata', 'Writing', 'Memo', 'determines', 'Father', 'B', 'ordinance', 'transgressed', 'subject', 'slaying', 'watches', 'site', 'repel', 'printed', 'pleasing', 'questions', 'molten', 'older', 'il', 'duration', 'vile', 'desiring', 'debugging', 'debug', 'dates', 'assistant', 'Accessible', 'arrives', 'Z', 'Strong', 'S%', 'Game', 'Continue', 'Ark', 'swore', 'rectitude', 'rests', 'range', 'polytheism', 'associating', 'pardoned', 'necked', 'mocked', 'lists', 'likewise', 'devout', 'deluded', 'border', 'bestows', 'attack', 'Trust', 'Nooh', 'unsubscribe', 'Majesty', 'Java', 'Egypt', 'Descendants', 'Auto', 'willingly', 'status%', 'surface', 'strengthened', 'Unread', 'storing', 'scroll', 'rebel', 'promises', 'player', 'niggardly', 'misery', 'leaving', 'note', 'guess', 'encoding', 'documents', 'dies', 'depart', 'causeth', 'camels', 'Burning', 'Beware', 'wants', 'swallowed', 'open%', 'surety', 'falling', 'snow', 'simple', 'disdain', 'shared', 'rebelled', 'parameter', 'maximum', 'loose', 'Repentance', 'kindred', 'intercessors', 'wall', 'innocent', 'include', 'ilaha', 'crime', 'fine', 'stern', 'extract', 'encryption', 'delay', 'deceived', 'averted', 'meanings', 'Wait', 'Subject', 'Sabbath', 'Remembrance', 'Location', 'Jabber', 'Forbearing', 'Email', 'CVS', 'waxed', 'connecting', 'victorious', 'Prophethood', 'verified', 'forelock', 'envy', 'stiff', 'river', 'label', 'expression', 'Face', 'dream', 'composer', 'condition', 'wronging', 'blazing', 'anot', 'growth', 'Words', 'entries', 'Serve', 'SMTP', 'Simplified', 'pair', 'Configure', 'conflicts', 'withdraw', 'scales', 'road', 'agreed', 'rained', 'proclaimed', 'veil', 'portents', 'notice', 'meaning', 'holding', 'heels', 'guests', 'feature', 'fasting', 'examples', 'cup', 'layer', 'corn', 'scale', 'begotten', 'attached', 'Saleh', 'Eisa', '-%', 'plainly', 'tool', 'Also', 'sorcery', 'sixth', 'script', 'BE', 'scourge', 'connections', 'restrained', 'recognise', 'minds', 'dpi', 'forgave', 'lightened', 'evident', 'blowing', 'overtook', 'bitter', 'abundantly', 'ancestors', 'adding', 'hence', 'hides', 'FITNESS', 'livelihood', 'accordance', 'adorned', 'Zakat', 'Unexpected', 'Ra', 'Days', 'submissive', 'Bug', 'Background', 'Vol', 'wages', 'ungodly', 'distinctly', 'twelve', 'tests', 'station', 'opinion', 'reserve', 'media', 'fullscreen', 'clothe', 'doeth', 'bond', 'compact', 'particular', 'closing', 'Allows', 'shadow', 'beneficent', '2001', 'www', 'disgraceful', 'transgressing', 'inserted', 'Download', 'tracks', 'therefor', 'silk', 'shame', 'reported', 'launch', 'statements', 'falls', 'failed:%', 'calendars', 'boy', 'accessible', 'Try', 'Like', 'Help', 'Too', 'Construct', 'Because', 'verify', 'section', 'extravagant', 'Configuration', 'popup', 'plead', 'ornaments', 'timeline', 'preference', 'lightning', 'husbands', 'Both', 'gift', 'distributed', 'bliss', 'arrived', 'afflict', 'endeavour', 'Whose', 'Sign', 'Obey', 'Build', 'Alif', 'won', 'planned', 'targets', 'spoke', 'intellect', 'presented', 'owners', 'nature', 'loan', 'consume', 'settle', 'caravan', 'kin', 'denying', 'finished', 'everlasting', 'debt', 'fearful', 'conversation', 'bore', 'ascribed', 'Disc', 'handle', 'abiding', 'humiliation', 'Saying', 'While', 'Lam', 'obligation', 'I:%', 'Directory', '9', 'Group', 'texture', 'rabbis', 'tasted', 'successors', 'err', 'spirit', 'speed', 'colour', 'vanity', 'sovereignty', 'query', 'mock', 'verse', 'enduring', 'lamp', 'identify', 'motion', 'generous', 'continued', 'expel', 'Loading', 'degrees', 'disaster', 'coordinate', 'altogether', 'locked', 'Account', 'warranty', 'supports', 'revive', 'rules', 'permitted', 'mount', 'animal', 'holds', 'habitations', 'draws', 'future', 'domain', 'devotion', 'turmoil', 'colors', 'cloud', 'broken', 'neck', 'Record', 'prior', 'subscribe', '19', 'stronger', 'stream', 'spoken', 'mean', 'shade', 'impatient', 'servers', 'reminded', 'Reclining', 'mockery', 'mere', 'heirs', 'happened', 'sleep', 'disbeliever', 'de', 'concern', 'cow', 'amount', 'presently', 'Theirs', 'A,%', 'Ignore', 'properly', 'sunrise', 'Glorified', 'plotted', 'photos', 'trade', 'nights', 'breathed', 'magicians', 'likely', 'error:%', 'dry', 'binding', 'Top', 'attachments', 'originated', 'rule', 'army', 'Tafsir', 'La', 'Key', 'arrows', 'Initial', 'Preferences', 'chief', 'Guardian', 'Blaze', 'zoom', 'supplied', 'infidelity', 'worked', 'tested', 'shelter', 'rewarded', 'resort', 'quality', 'paths', 'trumpet', 'mbox', 'hatred', 'guardians', 'flowing', 'canst', 'ignominy', 'Tar', 'Salih', 'Lut', 'identifier', 'Google', 'Arabs', 'transgression', 'rows', 'pieces', 'oppressed', 'hindered', 'merely', 'magician', 'enmity', 'Kind', 'MSN', 'configure', 'MB', 'Full', 'brasero', 'Yahoo', 'Sulaiman', 'broke', 'Print', 'Audio', 'developers', 'withhold', 'transfer', 'symbolic', 'filters', 'prison', 'mutual', 'mixed', 'l:%', 'obtain', 'determine', 'detail', 'camera', 'P', 'defer', 'begin', 'humility', 'apply', 'Possible', 'createth', 'Judgment', 'middle', 'Ah', 'World', 'wrongfully', 'whereat', 'suitable', 'spaces', 'shameful', 'rebellion', 'prostrating', 'hears', 'solemn', 'happen', 'filename', 'distance', 'creating', 'Local', 'counsel', 'Toggles', '2002', 'tag', 'cradle', 'spool', 'ends', 'updated', 'perhaps', 'guile', 'outcast', 'explanation', 'generation', 'constant', 'assign', 'armies', 'Blessed', 'Application', 'lifeless', 'madness', 'year', 'visit', 'immense', 'Capable', 'swallow', 'shirt', 'port', 'al', 'iron', 'affluent', 'disobedience', 'client', 'jest', 'belongeth', 'beasts', 'base', 'Shu', 'Preview', 'Other', 'Cartr', 'Empty', 'atom', 'via', 'treaty', 'rise', 'management', 'connected', 'loveth', 'languages', 'declined', 'explain', 'kindly', 'early', 'declare', 'trusts', '’’', 'uses', 'await', 'abundance', 'Toggle', 'grew', 'Sovereignty', 'generate', 'repeated', 'Settings', 'Read', 'desert', 'Header', 'worse', 'nay', 'functionality', 'mountain', 'exist', 'submit', 'granted', 'missing', 'device', 'filter', 'language', 'goods', 'mansions', 'certain', 'over', 'decrease', 'faces', 'severe', 'automatic', 'Object', 'corruption', 'fill', 'foster', 'encrypt', 'starting', 'Default', 'Bring', 'turning', 'minimum', 'out', 'Isaac', 'Preparing', 'wicked', 'establish', 'knows', 'whoso', 'fulfill', 'ascribe', 'Additional', 'Oft', 'Know', 'After', 'Choose', 'delight', 'portion', 'useful', 'cut', 'those', 'beneath', 'horizontally', 'windows', 'Number', 'Ask', 'prayed', 'preceded', 'H:%', 'hate', 'Password', 'calls', 'family', 'URL', 'values', 'Synchronize', 'works', 'judgement', 'heat', 'Powerful', 'generations', 'fills', 'judged', 'dear', 'initialize', 'expelled', 'went', 'takes', 'element', 'You', 'expects', 'seemed', 'Force', 'actor', 'firm', 'Database', 'slay', 'creatures', 'Godwary', 'Garden', 'seal', 'memo', 'cause', 'secret', 'Faith', 'speaks', 'lead', 'home', 'exercise', 'admonition', '51', 'fortune', 'revealed', 'hast', 'x', 'changed', 'thereof', 'reckon', 'cups', 'resource', 'clean', 'building', 'bondman', 'signs', '<pad>', 'soil', 'corrupt', 'commands', 'jinn', 'miserable', 'shadows', 'option', 'restrain', 'magic', 'ship', 'object', 'Make', 'Enable', 'us', 'point', 'cry', 'migrate', 'fearing', 'devoted', 'remote', 'following', 'appears', 'writable', 'couldst', 'burnt', 'perform', 'results', 'brings', 'Gods', 'terrible', 'cdrdao', 'Forward', 'fix', 'remembrance', 'Sacred', 'common', 'increase', 'Start', 'provide', 'knoweth', 'trunks', 'boiling', 'darkness', 'heavens', 'conditions', 'obedient', 'fruits', 'fulfilled', 'Syntax', 'ever', 'Said', 'roasted', 'silent', 'brothers', 'bondmen', 'scoff', 'forbid', 'rose', 'what', 'Christians', 'Outbox', 'poor', 'Update', 'Send', 'hasten', 'Opening', 'action', 'prompts', 'They', 'friends', 'apes', 'torment', 'Only', 'configuration', 'touching', 'easy', 'cried', 'heard', 'answer', 'greeting', 'regarding', 'Creation', 'hope', 'related', 'manifest', 'acted', 'contacts', 'Tree', 'wishes', 'thus', 'hiding', 'ruin', 'fare', 'understand', 'replace', 'manifold', 'etc', 'got', 'else', 'Check', 'code%', 'covenanted', 'append', 'pleased', 'defend', 'Ye', 'jinns', 'dust', 'fear', 'http', 'aid', 'default', 'swear', 'Even', 'placed', 'favoured', 'fair', 'sends', 'SIP', 'executable', 'disclosed', 'divorced', 'hearing', 'game', '2008', 'Remember', 'surrounded', 'fall', 'example', 'perfect', 'most', 'nobles', 'Apply', 'save', 'possessed', 'fast', 'Which', 'being', 'despised', 'c', 'wait', 'Custom', 'false', 'denied', 'caused', 'confederates', 'passing', 'going', 'respited', 'rest', 'merciful', 'morning', 'stand', 'grieve', 'disbelief', 'program', 'Answer', 'onto', 'prepared', 'Himself', 'desires', 'matter', 'twice', 'terminal', 'beside', 'Here', 'Bus', 'side', 'shaken', 'afraid', 'chosen', 'still', 'urge', 'persons', 'accepted', 'case', 'Checking', 'wretched', 'excepting', 'width', 'brand', 'custom', 'prays', 'wool', 'wholly', 'peoples', 'Look', 'pagans', 'video', 'food', 'cattle', 'dreams', 'under', 'paid', 'H', 'Copy', 'freezing', 'installation', 'Monotheism', 'version%', 'b', 'canceled', 'intercessor', 'crops', 'around', 'turns', 'distribution', 'bound', 'child', 'Jesus', 'host', 'accept', 'structure', 'reach', 'heed', 'perfected', 'Ibrahim', 'fatigue', 'therefore', 'evening', 'makes', 'found', '3', 'head', 'Eden', 'carry', 'position', 'afford', 'course', 'New', 'XML', 'Display', 'target', 'thou', 'dead', 'stay', 'thrones', 'Gabriel', 'bounty', 'Sunnah', 'guides', 'among', 'body', 'Message', 'madman', 'sound', 'available', 'feeds', 'wrongdoers', 'gone', 'warning', 'settings', 'willed', 's%', 'special', 'accepts', 'reckoning', 'Mary', 'presentation', 'reminder', 'deafness', 'crimes', 'An', 'state', 'beguiled', 'taught', 'mark', 'wisdom', 'during', 'barrier', 'rain', 'hearts', 'wrap', 'message', 'Throne', 'scatter', 'whereupon', 'secretly', 'whomsoever', 'falsehood', 'shown', 'some', 'space', 'remain', 'Qur', 'anything', 'medium', 'guilty', 'patron', 'Be', 'Out', 'long', 'didst', 'Unable', 'Harun', 'pay', 'clicking', 'select', 'thereupon', 'fault', 'sudden', 'index', 'Jews', 'kill', 'carried', 'exposed', 'supported', 'Copyright', 'lie', 'don', 'words', 'Increase', 'anguish', 'old', 'u', 'Thee', 'dedicated', 'Two', 'forgiving', 'committed', '/%', 'Prompt', 'plugin', 'recite', 'make', 'scriptures', 'working', 'Highlight', 'deleted', 'Fear', 'line', 'constantly', 'types', 'Search', 'liar', 'specified', 'far', 'does', 'Internet', 'news', 'Rain', 'License', 'occurs', 'devised', 'Run', 'helper', 'tree', 'faithless', 'trust', 'love', 'shell', '_', 'hell', 'believers', 'along', 'email', \"'\", 'succour', 'choose', 'very', 'times', 'built', 'Its', 'Noah', 'neighbour', 'twain', 'Encrypt', 'Folder', 'images', 'exists', 'forced', 'Still', 'key', 'below', 'stones', 'hinder', 'firmly', 'keeper', 'sons', 'period', 'anyone', 'patient', 'towns', 'nose', 'guidance', 'Messages', 'adds', 'mm', 'doom', 'numbered', 'fact', 'mislead', 'culprits', 'Set', 'haply', 'exult', 'the', 'stated', 'thanks', 'please', 'suddenly', 'Couldn', 'Apostle', 'order', 'pride', 'administrator', 'verses', 'empty', 'List', 'mightier', 'ordained', 'certainty', 'greater', 'enjoyed', 'memos', 'returns', 'Abraham', 'Allah', '32', 'kind', 'taketh', 'feel', 'Unseen', 'seed', 'knew', 'favours', 'within', 'recompense', 'the%', 'wonder', 'hide', 'appeared', 'dispute', 'protect', 'misfortune', 'himself', 'doth', 'wherewith', 'yourself', 'changes', 'three', 'bestowed', 'befall', 'drink', 'Jonah', 'shall', 'Truth', 'forgot', 'Their', 'how', 'just', 'Otherwise', 'art', 'completion', 'free', 'using', 'forces', 'Moses', 'box', 'breaks', 'barred', 'running', 'disabled', 'mosques', 'sitting', 'honourably', 'copy', 'kinds', 'covenant', 'Dhu', 'Noble', 'Decision', 'harm', 'Tux', 'returning', 'flags', 'decked', 'author', 'parents', 'surah', 'spend', 'gods', 'toward', 'desire', 'power', 'evidences', 'Mark', 'tell', 'place', 'mayest', 'gather', 'whereas', 'written', 'often', 'Floor', 'worldly', 'invents', 'bequest', 'wise', 'whoever', 'ranks', 'evildoers', 'justice', 'therein', 'rely', 'Muslim', 'aunts', 'term', 'change', 'repentance', 'removes', 'gardens', 'color', 'Warn', 'few', 'wronged', 'Gadu', 'protocol', 'Images', 'ownselves', 'Go', 'snippet', 'Shall', 'rehearsed', 'Retrieving', 'command', 'current', 'Alas', 'valid', 'clement', 'as', 'guard', 'contrived', 'better', 'to', 'lessons', 'males', 'has', '&', 's:%', 'fire', 'i.', 'Day', 'Windows', 'discourse', 'killed', 'reward', 'respond', 'given', 'deity', 'Browse', 'these', 'active', 'CDs', 'Compassionate', 'brief', 'diverse', 'females', 'thereby', 'charitable', 'Not', 'bring', 'service', '<bos>', 'human', 'forbade', 'could', 'Best', 'sending', 'Gardens', 'might', 'sanction', 'heedless', 'paper', 'Musa', 'measure', 'entering', 'if', 'There', 'behind', 'e.', 'With', 'aught', 'panel', 'east', 'guide', 'published', 'history', 'Draw', 'land', 'next', 'afterwards', 'keep', 'led', 'disobey', 'Therefore', 'Incomplete', 'About', 'striving', 'mothers', 'Whatsoever', 'sought', 'People', 'Welcome', 'worship', 'generic', 'want', 'reports', 'bestow', 'call', 'limited', 'years', 'well', 'its', 'together', 'came', 'me', 'are', 'pressing', 'new', 'Muhammad', 'enjoin', 'bearers', 'Travel', 'opened', 'That', 'Type', 'exception', 'pray', 'pane', 'Balance', 'sustenance', 'telling', 'curse', 'reciting', 'be', 'confused', 'Satans', 'soul', 'efforts', 'houses', 'rank', 'Those', 'passed', 'blow', 'bearer', 'A', 'theirs', 'neglectful', 'requested', 'born', 'correct', 'voice', 'dev', 'fight', 'between', 'reveals', 'rooms', 'listen', 'seeking', 'config', 'flow', 'Indeed', 'failed', 'bowed', 'sets', 'friend', 'her', 'Able', 'breasts', 'confirming', 'share', 'renamed', 'requires', 'view', 'Memory', 'word', 'Whenever', 'Can', 'pass', 'deceive', 'hath', 'proud', 'Pointer', 'n', 'saving', 'No', '15', 'hard', 'towards', 'zone', 'Or', 'right', 'See', 'strikes', 'Oneness', 'verily', 'created', 'Master', 'up', 'Verily', 'party', 'drive', 'crashed', 'clear', 'including', 'thereon', 'reject', 'our', 'advise', 'Torah', 'light', 'scheming', 'plugins', 'Worlds', 'scripture', 'angel', 'aforetime', 'why', 'and', 'divorce', 'abode', 'foundation', 'naught', 'much', 'Scripture', 'distant', 'thy', 'test', 'server%', 'reaches', 'marking', 'files', 'vegetation', 'thee', 'mercy', 'refuge', 'per', 'deleting', 'David', 'except', 'contains', 'sender', 'sight', 'am', 'it', 'humiliating', 'DVD', 'folder', 'Until', 'Haram', 'warn', 'surely', 'Junk', 'prevented', 'is', 'delivers', 'marriage', 's\":%', 'notify', 'Dawud', 'nor', 'bears', 'KDE', 'ye', 'gave', '/', 'skins', 'about', 'to%', 'will', 'LDAP', 'erase', 'recurring', 'mankind', 'Almighty', '’', 'ahead', 'commanded', 'maternal', 'proved', 'offline', 'auto', 'Remove', 'mailbox', 'European', 'Gracious', 'Certificate', 'town', 'superior', 'lodging', 'becomes', 'different', 'bookmarks', 'Do', 'live', 'Leave', 'Hour', 'palm', 'anniversary', 'peace', 'trusted', 'hidden', 'levels', 'Where', 'Paradise', 'Server', 'Immaculate', 'file', 'graves', 'married', 'Praiseworthy', 'day', 'all', 'important', 'problem', 'least', 'fly', 'Aware', 'wheresoever', '(', 'strange', 'load', 'Mosque', 'heart', 'coming', 'bringest', '—', 'said', 'Submit', 'issued', ';', 'It', 'Such', 'endure', '{', 'had', 'whomever', 'followed', 'Delay', 'raw', 'Get', 'wrong', 'elite', 'Forgiver', 'reached', 'riches', 'mighty', 'excuse', 'Al', 'admonish', 'Use', 'men', 'oil', 'rather', 'Council', '?', 'simply', \"s':%\", 'hostility', 'paternal', 'learn', 'ready', 'after', 'avail', 'unfaith', 'alms', 'doers', 'square', 'loves', 'Trumpet', 'equity', 'He', 'learned', 'springs', 'Another', 'daughters', 'Punishment', 'required', 'unto', 'against', 'earth', 'Lo', 'admonished', '2004', 'infidels', ':', 'Muttaqun', 'your', 'beguile', 'But', 'on', 'face', 'allowed', 'anger', 'female', 'expect', 'Him', 'God', 'quot', 'lied', 'wage', 'delivered', 'contact', '12', 'systems', 'subdued', 'clubs', 'from', 'inside', 'Software', 'Knower', 'memory', 'in', 'criterion', 'good', 'errors', 'must', 'replied', 'We', 'distress', 'variance', 'of', 'garments', 'Adam', 'Unto', 'downloaded', 'Wise', 'alignment', 'back', 'also', 'text', 'sincere', 'god', 'sync', 'Files', 'Way', 'my', 'removed', 'deaf', 'substitute', 'instead', 'Brasero', 'substance', 'needed', 'work', 'even', 'an', 'parable', 'Microsoft', 'charge', 'vines', '2000', 'their', 'continue', 'provision', 'explains', 'marvels', 'unexpectedly', ',', '“', 'near', 'them', 'payment', 'All', 'a', 'was', 'tempted', 'PARTICULAR', 'lest', 'before', 'Isra', 'proxy', 'six', 'woman', 'cometh', 'audio', '2', 'Mount', 'though', 'spread', 'Chinese', 'ships', 'complete', 'belonging', 'Screen', 'praise', 'My', 'cache', 'judges', '2005', 'bad', 'chose', 'page', 'so', 'close', 'viewer', 'recognised', 'his', 'Moosa', 'edited', 'CSV', 'whence', ']', 'ad', 'Save', 'seven', 'pure', 'Should', 'Surely', 'Owner', 'leads', 'album', 'wickedness', 'alternation', '%', 'hurt', 'there', 'answered', 'hallowed', 'pilgrimage', 'connect', 'world', 'eat', 'penalty', 'hands', 'nation', 'name', 'nations', 'commandment', 'into', 'sure', 'munificence', 'amongst', 'Nothing', 'disbelieves', 'On', 'you', 'present', 'believing', 'Believers', 'successfully', 'HTML', 'turn', 'Names', 'Include', 'thinking', 'task', 'earned', 'Home', 'activated', 'without', 'Injeel', 'His', 'random', 'him', 'Fir', 'Oh', 'front', 'version', 'knowest', 'actual', 'UID', 'latest', 'apostle', 'same', 'provisions', 'one', 'join', 'information', '):', \"'s\", 'remit', 'Enter', 'where', 'two', 'fail', 'Thamud', 'equal', 'offspring', 'immortal', 'decisive', 'slew', 'denies', 'should', 'with', 'time', 'duty', 'mortals', 'equitably', 'terms', 'people', 'while', 'lost', 'editor', 'mates', 'collection', '”', '\\\\\\\\\\\\\\\\', '6', 'everything', 'followers', 'For', 'Task', 'haste', 'follow', 'saw', 'sense', '-', 'plain', 'Merciful', 'C', 'directs', 'Clement', 'straight', 'extremely', 'see', 'geometry', 'standard', 'Koran', 'screen', 'than', 'Address', 'know', 'every', 'others', 'likeness', 'intercourse', 'Certainly', 'star', 'disbelievers', 'true', ')', 'house', '02110', 'marry', 'say', 'preview', 'come', 'occurred', 's', 'were', 'we', 'launchable', 'only', 'repeat', 'give', 'thirst', 'temporary', 'selected', 'grace', 'fee', 'Thou', 'deed', 'Evolution', 'e%', 'humbled', 'enjoyment', 'pagan', 'wives', 'If', 'obeys', 'Mohammed', 'Thread', 'names', 'visible', 'Month', 'link', 'above', 'Satan', 'From', 'glad', 'emerge', 'tray', 'thereto', 'slaves', 'apostles', 'debugger', 'tongue', 'I', 'Trash', 'forgotten', 'So', 'shortcut', 'justly', 'thankful', 'Thereupon', 'd', 'soon', 'prophet', 'repent', 'revert', 'unjust', 'amusement', 'Had', 'down', 'women', 'Right', '1', 'clothing', 'GroupWise', 'direction', 'Whoever', 'here', 'She', 'Outlook', 'things', 'pairs', 'PURPOSE', 'offering', 'meet', 'have', 'move', 'closed', 'told', 'left', 'man', 'mailing', 'Is', 'deeds', 'any', 'projects', 'Lord', 'devise', 'Umrah', 'set', 'Event', 'father', 'pledge', 'again', 'plot', 'trash', 'mountains', 'attain', 'witnesses', 'fabricate', 'flaming', 'appointed', 'Messengers', 'hypocrisy', 'safe', 'slave', 'whether', 'signed', 'honour', 'because', 'When', 'Our', 'record', 'Name', 'charity', 'Put', 'character', 'themselves', '–', 'destroyed', 'Most', 'Document', 'meeting', 'difficult', 'try', 'external', 'nine', 'spending', 'Whether', 'Could', 'ze', 'error', 'vector', 'benefit', 'cipher', 'flee', 'established', 'travelling', 'play', 'ground', 'compiler', 'passwords', 'Fire', 'but', '1301', 'tidings', 'black', 'become', 'cursor', 'four', 'compressed', 'use', 'birds', 'less', 'Yet', 'feareth', 'laden', 'standing', 'location', 'Anjuta', 'tab', 'Your', 'never', 'no', 'Supreme', 'waters', 'that', 'whatever', 'intercede', 'appointment', 'large', 'Messenger', 'effects', 'angels', 'As', 'go', 'To', 'through', 'parts', 'overtake', 'Us', 'conjecture', 'ere', 'wife', 'birth', 'gives', 'tasks', 'Drop', 'path', 'python', 'properties', 'vouchsafed', 'astray', 'associated', 'insert', 'root', 'strings', 'herein', 'Man', 'lo', 'favour', 'each', 'modify', 'session', 'fears', 'cast', 'unbelievers', 'ended', 'speak', 'Center', 'glorious', 'picture', 'fresh', 'send', 'Remote', 'ears', 'replaced', 'they', 'disbelieve', 'refrain', 'burned', 'final', 'image', 'creator', 'laudable', 'sin', 'listener', 'rock', 'awn', 'sufficient', 'able', 'server', 'Sets', 'idle', 'awaits', 'warner', 'remind', 'search', 'Click', 'many', 'function', 'control', 'Show', 'question', 'reply', 'Ishaq', 'oft', 'encompasses', 'support', 'configured', 'Simulation', 'SAW', 'Come', 'Hell', 'hair', 'recognized', 'glory', 'speech', 'needs', 'sell', 'when', 'scaling', 'despaired', 'whose', 'leave', 'disputed', 'devour', 'E', 'abide', 'Connection', 'waiting', 'AIM', 'Chapter', 'idolaters', 'Sufficient', 'neither', 'already', 'believed', 'hues', 'finds', 'care', 'prepare', '...', 'w', 'enemy', 'faith', 'hunger', 'unless', 'prayer', 'Mushrikun', 'secure', 'known', 'How', 'odd', 'homes', 'receipt', 'facing', 'aware', 'receive', 'Promise', 'document', 'due', 'contain', 'cell', 'in%', 'met', 'printer', 'whatsoever', 'Web', 'Resurrection', 'restart', 'by', 'enter', 'longer', 'patience', 'interest', 'small', 'heritage', 'progress', 'fully', 'brought', 'adultery', 'promise', 'Public', 'Open', 'guided', 'struck', 'nothing', '…', 'directory', 'animated', 'allegiance', 'Today', 'Judgement', 'sent', 'descendants', 'raise', 'perdition', 'packages', 'wish', 'righteous', 'repaid', 'great', 'Universe', 'Woe', 'yet', 'forwarded', 'description', 'ordered', 'profile', 'or', 'recited', 'Who', 'best', 'incoming', 'admitted', 'assuredly', 'project', 'Quran', 'sublime', 'number', 'earn', 'address', 'crucified', 'delete', 'such', 'ill', 'religion', '!', 'alive', 'module', 'Have', 'sign', 'city', 'buffer', 'button', 'giveth', 'families', 'Then', 'called', 'legal', 'disbelieved', 'Are', 'Hand', 'messengers', '<unk>', 'revelations', 'MAPI', 'channel', 'compose', 'used', 'former', 'Gog', 'children', 'servants', 'liars', 'purifies', '}', 'benefits', '‘', 'System', 'li', 'Select', 'books', 'operation', 'Allow', 'whosoever', 'seek', 'Books', 'Failed', 'chain', 'What', 'not', 'other', 'numbers', 'Till', 'punishment', 'excellent', 'scheme', 'form', 'seen', 'wealth', 'look', 'praying', 'yourselves', 'calendar', 'ingrate', 'burden', 'son', 'busy', 'seest', 'having', 'MiB', 'then', 'blessings', 'Would', 'Create', 'he', 'askest', 'data', 'Pharaoh', 'Zalimun', 'run', 'received', 'put', 'hand', 'indecency', '’s', 'resources', 'bar', 'Written', 'ransom', 'first', 'obey', 'seized', 'browser', 'Manual', 'serve', 'IP', 'dumb', 'wills', 'doubled', 'Last', 'rightly', 'source', 'for%', 'perish', 'been', 'grows', 'certainly', 'Muslims', 'belongs', 'dd', 'Photo', 'polytheists', 'painful', 'Forgiveness', 'she', 'CD', 'Refresh', 'goodly', 'happiness', 'window', 'Forgiving', 'fashioned', '+', 'mortal', 'Peace', 'claim', 'Thus', 'rivers', 'lend', 'forth', 'evil', 'feed', 'wound', 'printing', 'show', 'mail', 'vertical', 'godfearing', 'now', '[', 'part', 'Just', 'status', 'slander', 'despair', 'for', 'Tasks', 'this', 'end', 'Forgive', 'rewards', 'brother', 'spoils', 'regarded', 'through%', 'both', 'whom', 'turned', 'dog', 'Move', 'who', 'get', 'Subversion', 'Life', 'eyes', 'backend', 'Take', 'encounter', 'deny', 'group', 'heaven', 'persevere', 'off', 'By', 'obligatory', 'comes', 'remembering', 'earning', 'Prophet', 'according', '=', 'Changes', 'S', 'saved', '<eos>', 'days', 'Shift', 'living', 'poverty', 'another', 'File', '\\\\\\\\', 'knowingly', 'In', 'purchased', 'doubt', 'until', 'Will', 'Yea', 'creation', 'lies', 'forms', 'thing', 'tabs', 'sky', 'certificate', 'Table', 'lot', 'incline', 'user', 'joy', 'testify', 'Manager', 'One', 'engaged', 'besides', 'endowed', 'testimony', 'unset', 'done', 'read', 'Each', 'forgets', 'seas', 'type', 'settled', 'wrote', 'suffer', 'response', 'says', 'bear', 'Some', 'released', 'transgressors', 'beep', 'Export', 'selecting', 'invite', 'CMS', 'descends', 'aversion', 'Little', 'raised', 'Holy', 'Lot', 'dispersed', 'Assuredly', 'forgives', 'till', 'ungrateful', 'follows', 'folders', 'challenge', 'carrion', 'doing', 'forever', 'affair', 'means', 'equitable', 'weight', 'knowledge', 'Copying', 'allow', 'supreme', 'listed', 'taken', 'personal', 'someone', 'approach', 'occurrence', 'remove', 'ID', 'format', 'sun', 'grief', 'hear', 'disc', 'integrity', 'suppose', 'something', 'Why', 'certificates', 'relatives', 'scribe', 'wanted', 'separated', 'Turn', 'sister', 'misled', 'judge', 'destroy', 'too', 'photo', 'value', 'Mighty', 'blind', 'neglected', 'Before', 'taste', 'die', 'ties', 'inherit', 't', 'threw', 'alone', 'need', 'mind', 'Knowing', '.', 'really', 'messages', 'Light', 'Using', 'property', 'maildir', 'Please', 'little', 'upon', 'slain', 'Add', 'connection', 'keyboard', 'kingdom', 'Book', 'Sent', 'today', 'step', 'Grace', 'conceal', 'currently', 'Hereafter', 'reveal', 'paradise', 'pixmap', 'loss', 'prostration', 'R', 'Of', 'BAR', 'at', 'Time', 'treat', 'age', 'Switch', 'correctly', 'rejected', 'oaths', 'string', '5', 'Except', 'Invalid', 'beyond', 'Periods', 'dwell', 'struggle', 'Whom', 'thought', 'Honourable', 'topic', 'forward', 'prayers', 'column', 'tar', 'retain', 'Error', 'feet', 'Find', 'intense', 'Work', 'completed', 'belong', 'supporters', 'date', 'inform', 'Prayer', 'Nay', 'Ayat', 'checked', 'hosts', 'store', 'Disable', 'K', 'fighting', 'later', 'sake', 'presence', 'warned', 'thence', 'ways', 'made', 'Color', 'clay', 'sexual', 'revelation', 'drowned', 'manner', 'Does', 'whereof', 'mouths', 'Boston', 'proofs', 'once', 'bounties', 'negligent', 'manual', 'sins', 'wherefore', 'corrupted', 'Contact', 'PGP', 'believeth', 'drop', 'proclaim', 'excuses', 'absence', 'reflect', 'wilt', 'inspired', 'clipboard', 'confirmed', 'automatically', 'agony', 'enjoined', 'games', 'rage', 'forgiveness', 'thousand', 'community', 'M', 'ignorant', 'asunder', 'enabled', 'highlight', 'making', 'asked', 'Believe', 'needy', 'gushed', 'wind', 'oath', 'filled', 'Yes', 'Ever', 'item', 'setting', 'money', 'righteousness', 'Filter', 'breach', 'Envoys', 'videos', 'aib', 'Hearing', 'Mercy', 'knowing', 'access', 'blame', 'stars', 'understanding', 'shalt', 'worshipped', 'became', 'press', 'resting', 'blood', 'csv', 'fathers', 'nt', 'retribution', 'ward', 'pious', 'whenever', 'Herald', 'write', 'whole', 'development', 'Link', 'Nor', 'click', 'remaining', 'therewith', 'wide', 'main', 'vain', 'afar', 'Was', 'template', 'warnings', 'Path', 'Straight', 'find', 'parties', 'dialog', 'displayed', 'wo', 'gathered', 'deliver', 'Cast', 'O', 'fixed', 'conduct', 'size', 'of%', 'priests', 'displaying', 'obedience', 'lote', 'whereon', 'believer', 'Convert', 'low', 'worlds', 'idols', 'False', 'Seeing', 'Tab', 'recipient', 'contents', 'wine', 'installed', 'internal', 'trees', 'enables', 'A%', 'do', 'file%', 'unaware', 'Width', 'wrath', 'keys', 'larger', 'Alone', 'last', 'enjoy', 'Follow', 'create', 'Were', 'reading', 'inflicted', 'prophets', 'level', 'Inc.', 'accounts', 'Bounty', 'authentication', 'existing', 'Printer', 'helpers', 'grateful', 'aborted', 'sinners', 'ones', 'victory', 'Total', 'rebellious', 'Solomon', 'system', 'exalted', 'angle', 'periods', 'implied', 'submitted', 'respite', 'obeyed', 'gain', 'froward', 'male', 'content', 'entered', 'recipients', 'decide', 'punish', 'clouds', 'fat', 'Ad', 'Place', 'org', 'grow', 'aun', 'encrypted', 'witness', 'grant', 'build', 'assigned', 'truly', 'burn', 'sorcerer', 'permission', 'GNU', 'Contacts', 'Salat', 'extent', 'p', 'determined', 'authenticate', 'Children', 'calling', 'decreed', 'disable', 'hardship', 'items', 'past', 'restore', 'away', 'second', '00', 'touch', 'bed', 'weak', 'ICQ', 'The', 'X', 'Therefor', 'e', 'cursed', 'Chat', 'options', 'bits', 'Image', 'recall', 'expiation', 'sentence', 'security', 'bracelets', 'username', 'compel', 'tribes', 'death', 'attach', 'Data', 'similitude', 'belied', 'headers', 'Service', 'piety', 'virtuous', 'did', 'faithful', 'worst', 'recompensed', 'strength', 'sold', 'unknown', 'event', 'full', 'Witness', '8)', 'General', 'compared', 'thrown', 'icons', 'aright', 'colours', 'account', 'None', 'Prophets', 'burning', 'took', 'fonts', 'earlier', 'guardian', 'acts', 'thereafter', 'network', 'Edit', 'sounded', 'laws', 'widget', 'writing', 'life', 'sendeth', 'defy', 'manager', 'journey', 'natural', 'feared', 'questioned', '`', 'realize', 'Next', 'awe', 'length', 'observe', 'maketh', 'signature', 'prosper', 'lust', 'escape', 'bearing', 'notifications', 'overtakes', 'white', 'Aaron', 'tries', 'wast', 'Change', 'Hearer', 'members', 'desktop', 'utterly', 'behalf', 'from%', 'orphans', 'praises', 'convey', 'decree', 'equals', 'fourth', 'Close', 'throw', 'necessary', 'disgrace', 'specify', 'SpamAssassin', 'disk', 'hasty', 'watered', 'aside', 'rewritable', 'tryst', 'months', 'These', 'Clear', 'realise', 'argument', 's.', 'confirm', 'silver', 'groups', 'moving', 'grave', 'reason', 'utter', 'backs', 'Great', 'added', 'bewitched', 'return', 'believes', 'ratio', 'Specify', 'compassionate', 'folk', 'direct', 'affairs', 'backup', 'bones', 'release', 'hypocrites', 'sea', '*', 'consider', 'rename', 'Ya', 'Every', 'proof', 'camel', 'and%', 'pleasure', 'quit', 'Subscribe', 'track', 'wherever', 'Setup', 'belief', 'Glory', 'dwelling', 'archive', 'Window', 'progeny', 'moved', 'blessed', 'Arabic', 'invented', 'ease', 'reminders', 'preserve', 'bird', 'invalid', 'giving', 'alongside', 'let', 'height', 'fruit', 'which', 'killing', 'nigh', 'serpent', 'Spool', 'truthful', 'suffices', 'departed', 'steadfast', 'permanently', 'produce', 'Thy', 'permissions', 'Reminder', 'authority', 'addresses', 'database', 'intends', 'advantage', 'household', 'pre', 'toolbar', 'gates', 'Free', 'king', 'output', 'Qur’an', 'purified', 'inhabitants', 'Eat', 'Y', 'like', 'successful', 'bow', 'places', 'conspire', 'add', 'mention', 'cave', 'imported', 'Cause', 'woe', 'slaughter', 'vengeance', 'lofty', 'inheritance', '@', 'original', 'At', 'ruined', 'Jacob', 'mouse', 'requests', 'offered', 'private', 'throne', 'row', '8859', 'Authentication', 'start', 'night', 'indeed', 'Wherefore', 'Hajj', 'fell', 'ten', 'across', 'terror', 'IMAP', 'blessing', 'Browser', 'chat', 'draw', 'ISO', 'summary', 'Ar', 'goodness', 'check', 'taking', 'unseen', 'forty', 'browsing', 'forefathers', 'committing', 'Joseph', 'sees', 'timezone', 'upright', 'myself', 'possible', 'obligations', '~', 'subjected', 'table', 'users', 'wary', 'Manifest', 'destination', 'Command', 'take', 'humans', 'way', 'disbelieving', 'dwellers', 're', 'feeding', 'Say', 'hour', 'drives', 'mine', 'convert', 'moon', 'loading', 'Ekiga', 'lawful', 'prefer', 'patiently', 'Stop', '<', 'Behold', 'View', 'animals', 'Call', 'Let', 'preferred', 'Archive', 'mocking', 'area', 'advice', 'synchronize', 'avoid', 'CA', 'Protector', 'pardon', 'fellow', 'began', 'prescribed', 'trial', 'lines', 'angry', 'prostrated', 'theme', 'dawn', 'junk', 'license', 'alter', 'sisters', 'MIME', 'lookup', 'Maryam', 'tribe', 'mischief', 'highest', 'outgoing', 'round', 'strong', 'top', 'import', 'Attach', 'Knowledge', 'remained', 'double', 'Mankind', 'although', 'spades', 'always', 'folder:%', 'title', 'forsake', 'usury', 'prevent', 'library', 'sworn', 'treasures', 'stayed', 'single', 'Beneficent', 'axis', 'happy', 'clearly', 'Note', 'k', 'think', 'Page', 'month', 'locally', 'capture', 'dwellings', 'edit', 'folder%', 'threaten', 'comfort', 'log', 'menu', 'story', 'stop', 'talk', 'GNOME', 'perverted', 'break', 'pixels', 'powerful', 'Undoubtedly', 'rejoice', 'servant', '$', 'updates', 'bookmark', 'Among', 'resolve', '#', 'Empathy', 'Keep', 'matching', 'unsaved', 'roast', 'behold', 'Selected', 'Text', 'averse', 'limits', 'flock', 'URI', 'incurred', 'bottom', 'implemented', 'Yusuf', 'Worship', 'count', 'apart', 'glorify', 'seconds', 'appoint', 'deities', 'events', 'hire', 'safety', 'lay', 'map', 'Project', 'rising', 'POP', 'considered', 'g.', 'sub', 'can', 'i', 'split', 'm', 'changing', 'report', 'since', 'Y%', 'interval', 'fulfil', 'participants', 'mother', 'Give', 'affliction', 'devils', 'com', 'scum', 'open', 'flag', 'grievous', 'application', 'honourable', 'helps', 'crooked', 'non', 'prevail', 'Praise', 'clarify', 'ponder', 'Reply', 'Whatever', 'associates', 'portent', 'background', 'plants', 'befalls', 'input', 'laid', 'devil', 'worthy', 'mentioned', 'seize', 'overtaken', 'treasure', 'rescued', 'similar', 'believe', 'messenger', 'watch', 'fate', 'print', 'burdens', 'perceive', 'doer', 'success', 'statement', 'Automatically', 'supply', 'Creator', 'seeks', 'zakat', 'Iblis', 'Mode', 'list', 'V.', 'Device', 'saying', 'alarm', 'process', 'act', 'played', 'usage', 'sport', 'strive', 'cities', 'units', 'greatest', 'lesson', 'limit', 'womb', 'arrogant', 'Taste', 'heads', 'repay', 'online', 'started', 'saith', 'outward', 'request', 'wrongdoing', 'disobeyed', 'Word', 'expend', 'Repeat', 'exceed', 'surrendered', 'effect', 'intercession', 'shield', 'leaves', 'match', 'resurrected', 'cards', 'sinful', 'blindly', 'fellows', 'enough', 'tried', 'zero', 'Calendar', 'interface', 'Gospel', 'line%', 'outcome', 'True', 'bounds', 'spake', 'kingship', 'entry', 'characters', 'regard', 'belie', 'Islamic', 'attachment', 'Whoso', 'half', 'deviate', 'Undo', 'noble', 'blown', 'Has', 'card', 'Template', 'waves', 'commit', 'disclose', 'everyone', 'retrieve', 'befriend', 'winds', 'may', 'M:%', 'losers', 'companion', 'ear', 'heavy', 'judgment', 'conveyed', '>', 'Taurat', 'font', 'User', 'ancients', 'Gehenna', 'pages', 'room', 'separate', 'aided', 'style', 'center', 'entire', 'company', 'H.', 'therefrom', 'Never', 'Rather', 'exchange', 'Self', 'beware', 'Icon', 'Konqueror', 'Many', 'none', 'named', 'This', 'shows', 'recognize', 'B%', 'differ', 'grants', 'inmates', 'Shaitan', 'kindness', 'looking', 'anyway', 'notification', 'Received', 'code', 'iCalendar', 'Living', 'eye', 'gold', 'pattern', 'minutes', 'Me', 'parse', 'profit', 'observed', 'possess', 'sick', 'House', 'Nuh', 'Soon', 'betray', 'however', 'Play', 'disease', 'least%', 'maintain', 'attribute', 'seeing', 'grain', 'sorrow', 'law', 'trying', 'harvest', 'loaded', 'High', 'lame', 'King', 'increased', 'nearer', 'Delete', 'relative', 'seem', 'water', 'several', 'third', 'higher', 'alike', 'diamonds', 'Always', 'Judge', 'cool', 'Size', 'cover', '1:%', 'points', 'wherein', 'differed', 'band', 'exit', 'green', 'Well', 'goes', 'adversity', 'unable', 'interpretation', 'links', 'Searching', 'owner', 'otherwise', 'sacred', 'ourselves', 'regular', 'triumph', 'master', 'remains', 'web', 'prostrate', 'Exalted', 'respect', 'Firaun', 'lets', 'Islam', 'more', 'Makkah', 'traces', 'PKCS', 'war', 'forbidden', 'Unknown', 'Return', 'brethren', 'file:%', 'field', 'causes', 'guideth', 'showed', 'additional', 'd%', 'oblivious', 'garden', '8', 'fabricated', 'disobedient', 'begins', 'restored', 'convinced', 'Bad', 'lives', 'update', 'dark', 'associate', 'display', 'wished', 'spreading', 'souls', 'Proclaim', 'Did', '4', 'arguments', 'proposed', 'captives', 'desired', 'honoured', 'partners', 'And', 'selection', 'Hud', 'strayed', 'password', '10', 'decision', 'Hast', 'sensitive', 'abject', 'flesh', 'extension', 'seeming', 'concerning', 'beings', 'wet', 'enable', 'Plugin', 'overwrite', 'righteously', 'tongues', 'Guidance', 'drag', 'keepers', 'd%%', 'palms', 'spent', 'kinsmen', 'strike', 'bellies', 'DPI', 'mode', 'afterward', 'deceit', 'desist', 'sooth', 'injustice', 'lying', 'purpose', 'bare', 'possessions', 'sides', 'Now', 'plan', 'hallow', 'worshipping', 'spring', 'buttons', 'underneath', 'Mail', 'Neither', 'Upon', 'defined', 'sects', 'person', 'destruction', 'tarried', 'lord', 'register', 'gracious', 'humble', 'Israel', 'remember', 'lasting', 'overcome', 'slot', 'Position', 'stone', 'Tell', 'five', 'maybe', 'beautiful', 'layout', 'confirmation', 'message%', 'dominion', 'partner', 'Ctrl', 'WITHOUT', 'price', 'purify', 'destitute', 'mayst', 'Sending', 'walk', 'wombs', 'further', 'itself', 'self', 'setup', 'Install', 'locate', 'teach', 'ask', 'fields', 'Hidden', 'transgress', 'warners', 'visited', 'End', 'earnings', 'Ishmael', 'desireth', 'eight', 'orphan', 'agree', 'proper', 'Truly', 'software', 'Insert', 'Exchange', 'help', 'Messiah', 'chastise', 'Either', 'lose', 'deemed', 'returned', 'unjustly', 'Adding', 'fuel', 'forget', '7', 'promised', 'deniers', 'Incoming', 'D', 'applications', 'calf', 'grasp', 'joined', 'adornment', 'May', 'alpha', 'loads', 'header', 'leaders', 'arrive', 'offer', 'Spirit', 'misdeeds', 'factor', 'Status', 'provided', 'modified', 'force', 'yours', 'refused', 'details', 'icon', 'sort', 'Editor', 'township', 'footsteps', 'grapes', 'allies', 'on%', 'hold', 'informed', 'Fasiqun', 'openly', 'performed', 'plotting', 'punished', 'merchandise', 'scattered', 'Iesa', 'drawn', 'held', 'either', 'sacrifice', 'thine', 'Desktop', 'Foundation', 'own', 'Seer', 'rich', 'staff', 'unique', 'invoke', 'secrets', 'various', 'applied', 'appear', 'Current', 'belike', 'calamity', 'info', 'opening', 'companions', 'died', 'arms', 'objects', 'requited', 'reduce', 'necks', 'submission', 'would', 'Load', 'Saving', 'approaches', 'looks', 'a%', 'provides', 'canopy', 'Maybe', 'travel', 'Alamin', 'Evil', 'fought', 'deal', 'wrongdoer', 'succoured', 'marked', 'trustworthy', 'midst', 'delegate', 'marks', 'creates', 'sealed', 'short', 'Attachment', 'admit', 'sit', 'consequence', 'descend', 'bright', 'holy', 'wild', 'selves', '16', 'token', 'asking', 'Encryption', 'fallen', 'Signs', 'instance', 'lower', 'parent', 'Aye', 'Divinity', 'cease', 'Jibrael', 'unbelief', 'husband', 'startup', 'Reckoning', 'surrender', 'creature', 'argue', 'downloads', '0', 'rate', 'drinking', 'cancelation', 'forgive', 'helped', 'component', 'ignorance', 'proceed', 'login', 'enemies', 'stored', 'undoubtedly', 'revives', 'streams', 'Burn', 'Line', 'consequences', 'local', 'Purity', 'travelled', 'containing', 'afflictive', 'dreadful', 'bringeth', 'criminals', 'produced', 'download', 'nearest', 'driver', 'mac', 'execute', 'rotation', 'touched', 'protectors', 'recently', 'formed', 'succeed', 'Left', 'M%', 'Thereafter', 'fifth', 'editing', 'replying', 'UTF', 'smite', 'charged', 'Warning', 'cautious', 'based', 'actions', 'gate', 'calumny', 'truth', 'chastisement', 'covered', 'result', 'elements', 'horizontal', 'protector', 'advance', 'laugh', 'pleases', 'Hide', 'hundred', 'searching', 'virtue', 'compensation', 'previous', 'vision', 'abundant', 'exactly', 'balance', 'battle', 'install', 'multiple', 'normal', 'guarded', 'kept', 'pursued', 'Fit', 'thread', 'HTTP', 'matters', 'afflicted', 'awful', 'voices', 'computer', 'couches', 'decided', 'Verses', 'invent', 'distressed', 'jihad', 'high', 'package', 'arrogantly', 'Aad', 'bug', 'suffering', 'Maximum', 'swift', 'sequence', 'Therein', 'Reset', 'valley', 'Video', 'allows', 'increaseth', 'playing', 'barren', 'board', 'waste', 'befell', 'Though', 'likes', 'requite', 'hint', 'spouses', 'forgiven', 'week', 'Midian', 'Greek', 'SSL', 'book', 'driven', 'abiders', '\"', 'frustrate', 'minded', 'capacity', 'chiefs', 'hours', 'lock', 'increases', 'newsgroup', 'Import', 'protection', 'design', 'intendeth', 'Whosoever', 'refuse', 'stages', 'unlawful', 'evidence', 'avert', 'covering', 'divided'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(data):\n",
        "  hi_tensor_ = torch.tensor([vocab_transform['hi'][token] for token in hi_tokenizer(data)],\n",
        "                            dtype=torch.long)\n",
        "  return hi_tensor_"
      ],
      "metadata": {
        "id": "y_jwAhqzCixQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, IterableDataset, DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_, vocab_transform,token_transform):\n",
        "        self.data = []\n",
        "        # self.vocab = vocab\n",
        "        for index, row in data_.iterrows():\n",
        "            hi_sen = row['hindi_text']\n",
        "            en_sen = row['english_text']\n",
        "            hi_tensor_ = torch.tensor([vocab_transform['hi'][token] for token in hi_tokenizer(hi_sen)],\n",
        "                                    dtype=torch.long)\n",
        "            en_tensor_ = torch.tensor([vocab_transform['en'][token] for token in en_tokenizer(en_sen)],\n",
        "                                    dtype=torch.long)\n",
        "            self.data.append((hi_tensor_, en_tensor_))\n",
        "\n",
        "        \n",
        "        self.n_samples = len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index >= self.n_samples:\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "p7d2oaKQW4SE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data= MyDataset(trn_data,vocab_transform,token_transform)\n",
        "val_data = MyDataset(vl_data,vocab_transform,token_transform)"
      ],
      "metadata": {
        "id": "mt6QxBudraMq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpL-XG6gul3Z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "PAD_IDX = vocab_transform['hi']['<pad>']\n",
        "BOS_IDX = vocab_transform['hi']['<bos>']\n",
        "EOS_IDX = vocab_transform['hi']['<eos>']\n",
        "print(PAD_IDX,BOS_IDX,EOS_IDX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7SwSotzxu_D",
        "outputId": "2ccb6915-b3f3-4985-a087-e1c22578fbd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  hi_batch, en_batch = [], []\n",
        "  for (hi_item, en_item) in data_batch:\n",
        "    hi_batch.append(torch.cat([torch.tensor([BOS_IDX]), hi_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "  hi_batch = pad_sequence(hi_batch, padding_value=PAD_IDX)\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "  return hi_batch, en_batch\n",
        "\n",
        "train_iter = DataLoader(dataset = train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True,collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(dataset = val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True,collate_fn=generate_batch)\n",
        "# test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "#                        shuffle=True, collate_fn=generate_batch)"
      ],
      "metadata": {
        "id": "yB5VYdQ3rmxN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
        "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
        "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
        "                                        tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "metadata": {
        "id": "10x_6T_Rx20V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding +\n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "4CjUCgVMyDcK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[0]\n",
        "  tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "metadata": {
        "id": "8x3SiWITyG2r"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_VOCAB_SIZE = len(vocab_transform['hi'])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform['en'])\n",
        "EMB_SIZE = 64\n",
        "NHEAD = 1\n",
        "FFN_HID_DIM = 64\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 1\n",
        "NUM_DECODER_LAYERS = 1\n",
        "NUM_EPOCHS = 16\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
        "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
        "                                 FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
        ")"
      ],
      "metadata": {
        "id": "xoF3Gu8YyKoC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_iter, optimizer):\n",
        "  model.train()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in enumerate(train_iter):\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "\n",
        "      tgt_input = tgt[:-1, :]\n",
        "\n",
        "      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "      logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      tgt_out = tgt[1:,:]\n",
        "      loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      losses += loss.item()\n",
        "  return losses / len(train_iter)\n",
        "\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "  model.eval()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in (enumerate(valid_iter)):\n",
        "    src = src.to(device)\n",
        "    tgt = tgt.to(device)\n",
        "\n",
        "    tgt_input = tgt[:-1, :]\n",
        "\n",
        "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "    logits = model(src, tgt_input, src_mask, tgt_mask,\n",
        "                              src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "    tgt_out = tgt[1:,:]\n",
        "    loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "    losses += loss.item()\n",
        "  return losses / len(val_iter)"
      ],
      "metadata": {
        "id": "ctbcMaRMyRuD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 18\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "  start_time = time.time()\n",
        "  train_loss = train_epoch(transformer, train_iter, optimizer)\n",
        "  end_time = time.time()\n",
        "  val_loss = evaluate(transformer, valid_iter)\n",
        "  print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ],
      "metadata": {
        "id": "BSvmSMe4yugS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13211139-c36d-49d3-a52a-4db39f539985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 6.492, Val loss: 5.601, Epoch time = 39.554s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = process(src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "metadata": {
        "id": "kIoX5FACCDuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_sentence = \"ईमान लाओ और उसके रसूल के साथ होकर जिहाद करो\""
      ],
      "metadata": {
        "id": "3WLlZbPsEp3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = process(src_sentence)"
      ],
      "metadata": {
        "id": "D_qsiwvgBzpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(transformer, src_sentence))"
      ],
      "metadata": {
        "id": "p9f867EoE4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'transformer.pkl'\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(transformer, file)\n",
        "print(\"File saved successfully\")"
      ],
      "metadata": {
        "id": "mxhKcYkhE6VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "print(\"model loaded successfully\")"
      ],
      "metadata": {
        "id": "QlMGHrqnwcUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(loaded_model, \"ईमान लाओ और उसके रसूल के साथ होकर जिहाद करो\"))"
      ],
      "metadata": {
        "id": "jAPj7QwYwmtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_filename = 'answer.txt'\n",
        "count = 0\n",
        "with open(answer_filename, 'w', encoding = 'utf-8') as f:\n",
        "  for sentence in test['sentence']:\n",
        "    translated = translate(transformer, sentence)\n",
        "    # print(type(translated))\n",
        "    count+=1\n",
        "    f.write(translated + '\\n')"
      ],
      "metadata": {
        "id": "BjNaUoNdwvDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}